{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "088e1ea6-ad45-4475-a39f-adc93e00236d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import re\n",
    "import os\n",
    "from pathlib import Path\n",
    "import little_mallet_wrapper\n",
    "import seaborn\n",
    "import glob\n",
    "import random\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "path_to_mallet = \"/config/workspace/Dissertation/Dissertation/Data/mallet-2.0.8/bin/mallet\"\n",
    "pd.options.display.max_colwidth = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b7a6fcb-1341-4cba-89f9-d4935b20ff7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"3-18-21RedForEDtweetdata.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cd99eebf",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "644b6b61-5a57-41fd-9e0f-2e54ac0e675e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.date = pd.to_datetime(data.date, format='%m/%d/%y')\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "start_date = pd.to_datetime('01/01/18',format='%m/%d/%y')\n",
    "end_date = pd.to_datetime('12/31/19',format='%m/%d/%y')\n",
    "\n",
    "mask = (data['date'] > start_date) & (data['date'] <= end_date)\n",
    "data = data.loc[mask]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cc5f8d7-c1fc-4dc6-bc47-d171e831defb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tweet'] = data.tweet.map(lambda x: re.sub(r'(^|[^@\\w])@(\\w{1,15})\\b','',x))\n",
    "\n",
    "data['tweet'] = data['tweet'].map(lambda x: re.sub(r\"http\\S+\", '', x))\n",
    "\n",
    "data['tweet'] = data['tweet'].map(lambda x: re.sub(r'[^\\w\\s]', '', x))\n",
    "\n",
    "data['tweet'] = data['tweet'].map(lambda x: x.lower())\n",
    "\n",
    "data['tweet'] = data['tweet'].map(lambda x: re.sub('redfored', '', x))\n",
    "\n",
    "data['tweet'] = data['tweet'].map(lambda x: re.sub('red for ed', '', x))\n",
    "\n",
    "data = data.drop_duplicates(subset='tweet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fea1c6c-77c3-4b24-b697-705006223272",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = data['tweet'].astype(str)\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend([\"teacher\",\"teachers\",\"the\"])\n",
    "training_data = [little_mallet_wrapper.process_string(text, numbers='remove', stop_words=stop_words,remove_stop_words=True, remove_short_words=True) for text in data['tweet']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ecf6d3bb",
   "metadata": {},
   "source": [
    "### Train model (This takes ~4 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56afb3f-68ed-453f-95de-de9b5dc7abff",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = 16\n",
    "\n",
    "#Change to your desired output directory\n",
    "output_directory_path = 'topic-model-output'\n",
    "\n",
    "#No need to change anything below here\n",
    "Path(f\"{output_directory_path}\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "path_to_training_data           = f\"{output_directory_path}/training.txt\"\n",
    "path_to_formatted_training_data = f\"{output_directory_path}/mallet.training\"\n",
    "path_to_model                   = f\"{output_directory_path}/mallet.model.{str(num_topics)}\"\n",
    "path_to_topic_keys              = f\"{output_directory_path}/mallet.topic_keys.{str(num_topics)}\"\n",
    "path_to_topic_distributions     = f\"{output_directory_path}/mallet.topic_distributions.{str(num_topics)}\"\n",
    "\n",
    "little_mallet_wrapper.quick_train_topic_model(path_to_mallet, output_directory_path, num_topics, training_data)\n",
    "topic_distributions = little_mallet_wrapper.load_topic_distributions(path_to_topic_distributions)\n",
    "tweet_dict = dict(zip(training_data, data.tweet))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bbaeec5a",
   "metadata": {},
   "source": [
    "### Explore models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78970c95-a2a3-45f0-9a9e-cf289f328f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_top_tweets_per_topic(topic_number, number_of_documents):\n",
    "    \n",
    "    print(f\"✨Topic {topic_number}✨\\n\\n{topics[topic_number]}\\n\")\n",
    "\n",
    "    for probability, document in little_mallet_wrapper.get_top_docs(training_data, topic_distributions, topic_number, n=number_of_documents):\n",
    "        print(round(probability, 4), tweet_dict[document] + \"\\n\")\n",
    "    return\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "import re\n",
    "\n",
    "def display_bolded_topic_words_in_context(topic_number=3, number_of_documents=3, custom_words=None):\n",
    "\n",
    "    print(f\"✨Topic {topic_number}✨\\n\\n{topics[topic_number]}\\n\")\n",
    "\n",
    "    for probability, document in little_mallet_wrapper.get_top_docs(training_data, topic_distributions, topic_number, n=number_of_documents):\n",
    "\n",
    "        probability = f\"✨✨✨\\n\\n**{probability}**\"\n",
    "        original_text = tweet_dict[document]\n",
    "        original_text_lowered = original_text.lower()\n",
    "        topic_words = topics[topic_number]\n",
    "        topic_words = custom_words if custom_words != None else topic_words\n",
    "\n",
    "        for word in topic_words:\n",
    "            if word in original_text_lowered:\n",
    "                original_text = re.sub(f\"\\\\b{word}\\\\b\", f\"**{word.upper()}**\", original_text, flags=re.I)\n",
    "\n",
    "        display(Markdown(probability)), display(Markdown(original_text))\n",
    "    return"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bdecefd4",
   "metadata": {},
   "source": [
    "### Display All Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa412a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = little_mallet_wrapper.load_topic_keys(path_to_topic_keys)\n",
    "\n",
    "for topic_number, topic in enumerate(topics):\n",
    "    print(f\"✨Topic {topic_number}✨\\n\\n{topic}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "192e9464",
   "metadata": {},
   "source": [
    "### Use these methods for exploring a single topic in greater detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ba9131-79f1-4b86-99aa-07e82112bcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_to_explore = 11\n",
    "\n",
    "display_top_tweets_per_topic(topic_to_explore,1)\n",
    "display_bolded_topic_words_in_context(topic_number=topic_to_explore, number_of_documents=4)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6e9d0576",
   "metadata": {},
   "source": [
    "### Add time series data to topic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc8fdb11-e6ce-4e82-874b-d6dfb1abe7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = little_mallet_wrapper.load_topic_keys(path_to_topic_keys)\n",
    "topic_distributions = little_mallet_wrapper.load_topic_distributions(path_to_topic_distributions)\n",
    "data['topic_distributions'] = pd.Series(topic_distributions)\n",
    "topic_distributions_df = data['topic_distributions'].apply(pd.Series)\n",
    "topic_distributions_df.columns = [\" \".join(topic[:4]) for topic in topics]\n",
    "data = pd.concat([data, topic_distributions_df], axis=1)\n",
    "data['date'] = pd.to_datetime(data['date'])\n",
    "data['year'] = pd.to_datetime(data['date'].dt.year, format='%Y')\n",
    "data['year-month'] = data['date'].dt.to_period('M')\n",
    "data['Date (by month)'] = [month.to_timestamp() for month in data['year-month']]\n",
    "\n",
    "data = data.set_index('Date (by month)')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "64bddd2e",
   "metadata": {},
   "source": [
    "### Create a graph for each topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f72371-78b3-436a-8d68-199e9b4f5c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(0,num_topics):\n",
    "    topic_number = x\n",
    "    topic_label = \" \".join(topics[topic_number][:4])\n",
    "    data.groupby(data.index)[[topic_label]].mean().plot(title=f'RedForEd Tweets By Topic', linewidth=3, color=\"red\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('ds')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "64a3776662997a24a2ed087fc314d1fb0ced86b8ae78a59009a03d7b36ffebb7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
